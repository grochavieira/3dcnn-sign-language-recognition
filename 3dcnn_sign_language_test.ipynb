{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "h9zjm94r8qr7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import argparse\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import ndimage\n",
    "from tensorflow.python.client import device_lib\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checa se a GPU está sendo usada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variáveis Globais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size        = 185 * 2 # Tamanho dos dados para treinamento\n",
    "test_size         = 40 # Tamanho dos dados para teste\n",
    "max_vid_per_class = 20 # Número máximo de vídeos por classe\n",
    "batch_size        = train_size + test_size # Tamanho total dos dados de treinamento e validação 577\n",
    "num_of_frames     = 12  # Número de frames que o vídeo será dividido\n",
    "width             = 64  # Largura da imagem\n",
    "height            = 48  # Altura da imagem\n",
    "num_of_channels   = 1   # Número de canais da imagem (cinza, RGB, etc.)\n",
    "num_of_classes    = 2  # Número de classes que serão utilizadas\n",
    "test_percentage   = 0.2 # Porcentagem utilizada para a qtd de dados para teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes (Apenas Vídeo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    \"Acontecer\"   : 0, \n",
    "    \"Aluno\"       : 1, \n",
    "    \"Amarelo\"     : 2, \n",
    "    'America'     : 3, \n",
    "    'Aproveitar'  : 4,\n",
    "    \"Bala\"        : 5, \n",
    "    \"Banco\"       : 6, \n",
    "    \"Banheiro\"    : 7, \n",
    "    \"Barulho\"     : 8, \n",
    "    \"Cinco\"       : 9,\n",
    "    \"Conhecer\"    : 10, \n",
    "    \"Espelho\"     : 11, \n",
    "    \"Esquina\"     : 12, \n",
    "    \"Filho\"       : 13, \n",
    "    \"Maca\"        : 14, \n",
    "    \"Medo\"        : 15,\n",
    "    \"Ruim\"        : 16, \n",
    "    \"Sapo\"        : 17, \n",
    "    \"Vacina\"      : 18, \n",
    "    \"Vontade\"     : 19\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes (Apenas Imagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    \"A\"   : 0,\n",
    "    \"B\"   : 1,\n",
    "    \"C\"   : 2,\n",
    "    \"D\"   : 3,\n",
    "    \"E\"   : 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes (Vídeos e Imagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {\n",
    "    \"A\"           : 0,\n",
    "    \"Acontecer\"   : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação dos vídeos e imagens para treinamento e teste (junto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'Acontecer']\n",
      "\n",
      "===== A =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "\n",
      "===== FIM DA CLASSE =====\n",
      "\n",
      "\n",
      "===== Acontecer =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "\n",
      "===== FIM DA CLASSE =====\n",
      "\n",
      "\n",
      "\n",
      "===== FIM =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "X_data = [] # armazena os frames\n",
    "Y_data = [] # armazena as labels\n",
    "\n",
    "video_type = '.mp4'\n",
    "\n",
    "angles = [-20, -10, -5, 5, 10, 20] # Define alguns ângulos para rotação\n",
    "\n",
    "video_classes   = './LIBRAS-Dataset/' # caminho da pasta com os arquivos\n",
    "list_of_classes = os.listdir(video_classes) # pega o nome de todos os arquivos dentro da pasta\n",
    "print(list_of_classes)\n",
    "\n",
    "class_counter = 0\n",
    "for k in list_of_classes:\n",
    "    if (class_counter >= num_of_classes):\n",
    "        break\n",
    "    \n",
    "    class_counter = class_counter + 1\n",
    "    \n",
    "    X_dummy = []\n",
    "    Y_dummy = []\n",
    "    \n",
    "    video_folder   = str(video_classes + k + '/')\n",
    "    list_of_videos = os.listdir(video_folder)\n",
    "    \n",
    "    contador = 0\n",
    "    \n",
    "    print('\\n===== ' + k + ' =====\\n')\n",
    "    \n",
    "    # pega o nome de cada arquivo de vídeo e passa para transformar em frames\n",
    "    for i in list_of_videos:\n",
    "        if contador >= max_vid_per_class:\n",
    "            print('\\n\\n===== FIM DA CLASSE =====\\n')\n",
    "            break\n",
    "            \n",
    "        contador = contador + 1\n",
    "        \n",
    "        isVideo = False\n",
    "        \n",
    "        if video_type in i:\n",
    "            isVideo = True\n",
    "            \n",
    "        if (isVideo):\n",
    "            vid = str(video_folder + i) # caminho do vídeo\n",
    "            cap = cv2.VideoCapture(vid) # lê o vídeo\n",
    "            \n",
    "            # pega o tamanho do vídeo em milisegundos e divide pela\n",
    "            # quantidade de frames para descobrir o tempo que deve ser\n",
    "            # pego cada frame\n",
    "            fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "            frame_count  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            duration     = frame_count/fps\n",
    "            seconds      = frame_count/fps;\n",
    "            miliseconds  = seconds * 1000\n",
    "            frame_moment = int(miliseconds/num_of_frames)\n",
    "        else:\n",
    "            vid = str(video_folder + i) # caminho do arquivo\n",
    "            cap = cv2.imread(vid) # lê o arquivo   \n",
    "        \n",
    "        frames        = [] # armazenar os frames\n",
    "        #rotatedFrames = [] # armazenar os frames distorcidos\n",
    "        \n",
    "        count = 0 # contador para pegar cada frame\n",
    "        \n",
    "        #angle = random.choice(angles) # escolhe aleatóriamente um ângulo\n",
    "        for j in range(num_of_frames): # aqui pegamos n frames de acordo com num_of_frames\n",
    "            \n",
    "            if (isVideo):\n",
    "                cap.set(cv2.CAP_PROP_POS_MSEC,(count*frame_moment)) # seta o momento do vídeo para pegar o frame\n",
    "                ret, frame = cap.read() # pega de fato o frame, e se deu sucesso ou não\n",
    "            \n",
    "                if ret == True: # se deu sucesso...\n",
    "                    print('S=>', end=\"\")\n",
    "                    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # converte o frame para cinza\n",
    "                    frame = cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA) # redimensiona o frame\n",
    "                    frames.append(frame.tolist()) # adiciona o frame para o vetor de frames\n",
    "                    #rotatedFrame = ndimage.rotate(frame, angle, reshape=False)\n",
    "                    #rotatedFrames.append(rotatedFrame)\n",
    "                else:\n",
    "                    print('*E*=>', end=\"\")\n",
    "            else:\n",
    "                print('S=>', end=\"\")\n",
    "\n",
    "                frame = cv2.cvtColor(cap, cv2.COLOR_BGR2GRAY) # converte o frame para cinza\n",
    "                frame = cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA) # redimensiona o frame\n",
    "                frames.append(frame.tolist()) # adiciona o frame para o vetor de frames\n",
    "                \n",
    "            count = count + 1\n",
    "            \n",
    "        X_dummy.append(frames) # adiciona todos os frames de um vídeo\n",
    "        Y_dummy.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "    \n",
    "    X_data.append(X_dummy)\n",
    "    Y_data.append(Y_dummy)\n",
    "    #X_data.append(rotatedFrames) # adiciona todos os frames de um vídeo\n",
    "    #Y_data.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "    \n",
    "print('\\n\\n===== FIM =====\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação das imagens para treinamento e teste (junto)\n",
    "- Aqui é pego todos os dados juntos, para que a separação entre treino e teste possa ser feita depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E']\n",
      "\n",
      "===== A =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== B =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== C =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== D =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== E =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "\n",
      "===== FIM =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "X_data = [] # armazena os frames\n",
    "Y_data = [] # armazena as labels\n",
    "\n",
    "angles = [-20, -10, -5, 5, 10, 20] # Define alguns ângulos para rotação\n",
    "\n",
    "video_classes   = './LIBRAS-Dataset-Images/' # caminho da pasta com os arquivos\n",
    "list_of_classes = os.listdir(video_classes) # pega o nome de todos os arquivos dentro da pasta\n",
    "print(list_of_classes)\n",
    "\n",
    "class_counter = 0\n",
    "for k in list_of_classes:\n",
    "    if (class_counter >= num_of_classes):\n",
    "        break\n",
    "    \n",
    "    class_counter = class_counter + 1\n",
    "    \n",
    "    X_dummy = []\n",
    "    Y_dummy = []\n",
    "    \n",
    "    video_folder   = str(video_classes + k + '/')\n",
    "    list_of_videos = os.listdir(video_folder)\n",
    "    \n",
    "    contador = 0\n",
    "    \n",
    "    print('\\n===== ' + k + ' =====\\n')\n",
    "    \n",
    "    # pega o nome de cada arquivo de vídeo e passa para transformar em frames\n",
    "    for i in list_of_videos:\n",
    "        if contador >= max_vid_per_class:\n",
    "            print('\\n\\n===== FIM DA CLASSE =====\\n')\n",
    "            break\n",
    "            \n",
    "        contador = contador + 1\n",
    "        \n",
    "        vid = str(video_folder + i) # caminho do vídeo\n",
    "        cap = cv2.imread(vid) # lê o vídeo\n",
    "        \n",
    "        # pega o tamanho do vídeo em milisegundos e divide pela\n",
    "        # quantidade de frames para descobrir o tempo que deve ser\n",
    "        # pego cada frame\n",
    "#         fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "#         frame_count  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#         duration     = frame_count/fps\n",
    "#         seconds      = frame_count/fps;\n",
    "#         miliseconds  = seconds * 1000\n",
    "#         frame_moment = int(miliseconds/num_of_frames)\n",
    "        \n",
    "        frames        = [] # armazenar os frames\n",
    "#         rotatedFrames = [] # armazenar os frames distorcidos\n",
    "        \n",
    "        count = 0 # contador para pegar cada frame\n",
    "        \n",
    "        angle = random.choice(angles) # escolhe aleatóriamente um ângulo\n",
    "        for j in range(num_of_frames): # aqui pegamos n frames de acordo com num_of_frames\n",
    "#             cap.set(cv2.CAP_PROP_POS_MSEC,(count*frame_moment)) # seta o momento do vídeo para pegar o frame\n",
    "#             ret, frame = cap.read() # pega de fato o frame, e se deu sucesso ou não\n",
    "            \n",
    "#             if ret == True: # se deu sucesso...\n",
    "            print('S=>', end=\"\")\n",
    "\n",
    "            frame = cv2.cvtColor(cap, cv2.COLOR_BGR2GRAY) # converte o frame para cinza\n",
    "            frame = cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA) # redimensiona o frame\n",
    "            frames.append(frame.tolist()) # adiciona o frame para o vetor de frames\n",
    "            #rotatedFrame = ndimage.rotate(frame, angle, reshape=False)\n",
    "            #rotatedFrames.append(rotatedFrame)\n",
    "                \n",
    "#             else:\n",
    "#                 print('*E*=>', end=\"\")\n",
    "                \n",
    "            count = count + 1\n",
    "            \n",
    "        X_dummy.append(frames) # adiciona todos os frames de um vídeo\n",
    "        Y_dummy.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "    \n",
    "    X_data.append(X_dummy)\n",
    "    Y_data.append(Y_dummy)\n",
    "    #X_data.append(rotatedFrames) # adiciona todos os frames de um vídeo\n",
    "    #Y_data.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "    \n",
    "print('\\n\\n===== FIM =====\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação dos frames de vídeos para treinamento e teste (junto)\n",
    "- Aqui é pego todos os dados juntos, para que a separação entre treino e teste possa ser feita depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não pode encontrar o caminho especificado: './LIBRAS-Dataset/Treino/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5608/1042107292.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mvideo_classes\u001b[0m   \u001b[1;33m=\u001b[0m \u001b[1;34m'./LIBRAS-Dataset/Treino/'\u001b[0m \u001b[1;31m# caminho da pasta com os arquivos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mlist_of_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_classes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# pega o nome de todos os arquivos dentro da pasta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema não pode encontrar o caminho especificado: './LIBRAS-Dataset/Treino/'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "X_data = [] # armazena os frames\n",
    "Y_data = [] # armazena as labels\n",
    "\n",
    "angles = [-20, -10, -5, 5, 10, 20] # Define alguns ângulos para rotação\n",
    "\n",
    "video_classes   = './LIBRAS-Dataset/Treino/' # caminho da pasta com os arquivos\n",
    "list_of_classes = os.listdir(video_classes) # pega o nome de todos os arquivos dentro da pasta\n",
    "print(list_of_classes)\n",
    "\n",
    "class_counter = 0\n",
    "for k in list_of_classes:\n",
    "    if (class_counter >= num_of_classes):\n",
    "        break\n",
    "    \n",
    "    class_counter = class_counter + 1\n",
    "    \n",
    "    X_dummy = []\n",
    "    Y_dummy = []\n",
    "    \n",
    "    video_folder   = str(video_classes + k + '/')\n",
    "    list_of_videos = os.listdir(video_folder)\n",
    "    \n",
    "    contador = 0\n",
    "    \n",
    "    print('\\n===== ' + k + ' =====\\n')\n",
    "    \n",
    "    # pega o nome de cada arquivo de vídeo e passa para transformar em frames\n",
    "    for i in list_of_videos:\n",
    "        if contador >= max_vid_per_class:\n",
    "            print('\\n\\n===== FIM DA CLASSE =====\\n')\n",
    "            break\n",
    "            \n",
    "        contador = contador + 1\n",
    "        \n",
    "        vid = str(video_folder + i) # caminho do vídeo\n",
    "        cap = cv2.VideoCapture(vid) # lê o vídeo\n",
    "        \n",
    "        # pega o tamanho do vídeo em milisegundos e divide pela\n",
    "        # quantidade de frames para descobrir o tempo que deve ser\n",
    "        # pego cada frame\n",
    "        fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration     = frame_count/fps\n",
    "        seconds      = frame_count/fps;\n",
    "        miliseconds  = seconds * 1000\n",
    "        frame_moment = int(miliseconds/num_of_frames)\n",
    "        \n",
    "        frames        = [] # armazenar os frames\n",
    "        rotatedFrames = [] # armazenar os frames distorcidos\n",
    "        \n",
    "        count = 0 # contador para pegar cada frame\n",
    "        \n",
    "        angle = random.choice(angles) # escolhe aleatóriamente um ângulo\n",
    "        for j in range(num_of_frames): # aqui pegamos n frames de acordo com num_of_frames\n",
    "            cap.set(cv2.CAP_PROP_POS_MSEC,(count*frame_moment)) # seta o momento do vídeo para pegar o frame\n",
    "            ret, frame = cap.read() # pega de fato o frame, e se deu sucesso ou não\n",
    "            \n",
    "            if ret == True: # se deu sucesso...\n",
    "                print('S=>', end=\"\")\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # converte o frame para cinza\n",
    "                frame = cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA) # redimensiona o frame\n",
    "                frames.append(frame.tolist()) # adiciona o frame para o vetor de frames\n",
    "                #rotatedFrame = ndimage.rotate(frame, angle, reshape=False)\n",
    "                #rotatedFrames.append(rotatedFrame)\n",
    "                \n",
    "            else:\n",
    "                print('*E*=>', end=\"\")\n",
    "                \n",
    "            count = count + 1\n",
    "            \n",
    "        X_dummy.append(frames) # adiciona todos os frames de um vídeo\n",
    "        Y_dummy.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "    \n",
    "    X_data.append(X_dummy)\n",
    "    Y_data.append(Y_dummy)\n",
    "    #X_data.append(rotatedFrames) # adiciona todos os frames de um vídeo\n",
    "    #Y_data.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "    \n",
    "print('\\n\\n===== FIM =====\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação dos frames de vídeos para treino (separado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acontecer', 'Aluno', 'Amarelo', 'America', 'Aproveitar', 'Bala', 'Banco', 'Banheiro', 'Barulho', 'Cinco', 'Conhecer', 'Espelho', 'Esquina', 'Filho', 'Maca', 'Medo', 'Ruim', 'Sapo', 'Vacina', 'Vontade']\n",
      "\n",
      "===== Acontecer =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Aluno =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Amarelo =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== America =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Aproveitar =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Bala =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Banco =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Banheiro =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Barulho =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Cinco =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Conhecer =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Espelho =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Esquina =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Filho =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Maca =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Medo =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Ruim =====\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Sapo =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Vacina =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Vontade =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "\n",
      "===== FIM =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "X_data_train = [] # armazena os frames\n",
    "Y_data_train = [] # armazena as labels\n",
    "angles = [-20, -10, -5, 5, 10, 20] # Define alguns ângulos para rotação\n",
    "\n",
    "video_classes   = './LIBRAS-Dataset-2/Treino/' # caminho da pasta com os arquivos\n",
    "list_of_classes = os.listdir(video_classes) # pega o nome de todos os arquivos dentro da pasta\n",
    "print(list_of_classes)\n",
    "\n",
    "class_counter = 0\n",
    "for k in list_of_classes:\n",
    "    if (class_counter >= num_of_classes):\n",
    "        break\n",
    "        \n",
    "    class_counter = class_counter + 1\n",
    "    \n",
    "    video_folder   = str(video_classes + k + '/')\n",
    "    list_of_videos = os.listdir(video_folder)\n",
    "    \n",
    "    contador = 0\n",
    "    \n",
    "    print('\\n===== ' + k + ' =====\\n')\n",
    "    \n",
    "    # pega o nome de cada arquivo de vídeo e passa para transformar em frames\n",
    "    for i in list_of_videos:\n",
    "        if contador >= max_vid_per_class:\n",
    "            print('\\n\\n===== FIM DA CLASSE =====\\n')\n",
    "            break\n",
    "            \n",
    "        contador = contador + 1\n",
    "        \n",
    "        vid = str(video_folder + i) # caminho do vídeo\n",
    "        cap = cv2.VideoCapture(vid) # lê o vídeo\n",
    "        \n",
    "        # pega o tamanho do vídeo em milisegundos e divide pela\n",
    "        # quantidade de frames para descobrir o tempo que deve ser\n",
    "        # pego cada frame\n",
    "        fps          = cap.get(cv2.CAP_PROP_FPS)\n",
    "        frame_count  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        duration     = frame_count/fps\n",
    "        seconds      = frame_count/fps;\n",
    "        miliseconds  = seconds * 1000\n",
    "        frame_moment = int(miliseconds/num_of_frames)\n",
    "        \n",
    "        frames        = [] # armazenar os frames\n",
    "        rotatedFrames = [] # armazenar os frames distorcidos\n",
    "        \n",
    "        count = 0 # contador para pegar cada frame\n",
    "        \n",
    "        angle = random.choice(angles) # escolhe aleatóriamente um ângulo\n",
    "        \n",
    "        for j in range(num_of_frames): # aqui pegamos n frames de acordo com num_of_frames\n",
    "            cap.set(cv2.CAP_PROP_POS_MSEC,(count*frame_moment)) # seta o momento do vídeo para pegar o frame\n",
    "            ret, frame = cap.read() # pega de fato o frame, e se deu sucesso ou não\n",
    "            \n",
    "            if ret == True: # se deu sucesso...\n",
    "                print('S=>', end=\"\")\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # converte o frame para cinza\n",
    "                frame = cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA) # redimensiona o frame\n",
    "                frames.append(frame.tolist()) # adiciona o frame para o vetor de frames\n",
    "                rotatedFrame = ndimage.rotate(frame, angle, reshape=False)\n",
    "                rotatedFrames.append(rotatedFrame.tolist())\n",
    "                \n",
    "            else:\n",
    "                print('*E*=>', end=\"\")\n",
    "                \n",
    "            count = count + 1\n",
    "            \n",
    "        X_data_train.append(frames) # adiciona todos os frames de um vídeo\n",
    "        Y_data_train.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "        X_data_train.append(rotatedFrames) # adiciona todos os frames de um vídeo\n",
    "        Y_data_train.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "        \n",
    "print('\\n\\n===== FIM =====\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformação dos frames de vídeos para teste (separado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Acontecer', 'Aluno', 'Amarelo', 'America', 'Aproveitar', 'Bala', 'Banco', 'Banheiro', 'Barulho', 'Cinco', 'Conhecer', 'Espelho', 'Esquina', 'Filho', 'Maca', 'Medo', 'Ruim', 'Sapo', 'Vacina', 'Vontade']\n",
      "\n",
      "===== Acontecer =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Aluno =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Amarelo =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== America =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Aproveitar =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Bala =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Banco =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Banheiro =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Barulho =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Cinco =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Conhecer =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Espelho =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Esquina =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Filho =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Maca =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Medo =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Ruim =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Sapo =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Vacina =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "===== Vontade =====\n",
      "\n",
      "S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>S=>\n",
      "\n",
      "===== FIM =====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "\n",
    "X_data_test = [] # armazena os frames\n",
    "Y_data_test = [] # armazena as labels\n",
    "\n",
    "video_classes   = './LIBRAS-Dataset-2/Teste/' # caminho da pasta com os arquivos\n",
    "list_of_classes = os.listdir(video_classes) # pega o nome de todos os arquivos dentro da pasta\n",
    "print(list_of_classes)\n",
    "\n",
    "class_counter = 0\n",
    "\n",
    "for k in list_of_classes:\n",
    "    if (class_counter >= num_of_classes):\n",
    "        break\n",
    "        \n",
    "    class_counter = class_counter + 1\n",
    "    \n",
    "    video_folder   = str(video_classes + k + '/')\n",
    "    list_of_videos = os.listdir(video_folder)\n",
    "    \n",
    "    contador = 0\n",
    "    \n",
    "    print('\\n===== ' + k + ' =====\\n')\n",
    "    \n",
    "    # pega o nome de cada arquivo de vídeo e passa para transformar em frames\n",
    "    for i in list_of_videos:\n",
    "        if contador >= max_vid_per_class:\n",
    "            print('\\n\\n===== FIM DA CLASSE =====\\n')\n",
    "            break\n",
    "            \n",
    "        contador = contador + 1\n",
    "        \n",
    "        vid = str(video_folder + i) # caminho do vídeo\n",
    "        cap = cv2.VideoCapture(vid) # lê o vídeo\n",
    "        \n",
    "        frames = [] # armazenar os frames\n",
    "        \n",
    "        count = 0 # contador para pegar cada frame\n",
    "        \n",
    "        for j in range(num_of_frames): # aqui pegamos n frames de acordo com num_of_frames\n",
    "            cap.set(cv2.CAP_PROP_POS_MSEC,(count*250)) # seta o momento do vídeo para pegar o frame\n",
    "            ret, frame = cap.read() # pega de fato o frame, e se deu sucesso ou não\n",
    "            \n",
    "            if ret == True: # se deu sucesso...\n",
    "                print('S=>', end=\"\")\n",
    "                \n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # converte o frame para cinza\n",
    "                frame = cv2.resize(frame,(width,height),interpolation=cv2.INTER_AREA) # redimensiona o frame\n",
    "                frames.append(frame.tolist()) # adiciona o frame para o vetor de frames\n",
    "                \n",
    "            else:\n",
    "                print('*E*=>', end=\"\")\n",
    "                \n",
    "            count = count + 1\n",
    "            \n",
    "        X_data_test.append(frames) # adiciona todos os frames de um vídeo\n",
    "        Y_data_test.append(class_names[k]) # adiciona a label do conjunto de frames\n",
    "\n",
    "print('\\n\\n===== FIM =====\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checar se vetor é instância de numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(isinstance(X_data[0][0][0], np.ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar os Dados em JSON (junto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with open('./video-classes/X_data.json', 'w') as f:\n",
    "    json.dump(X_data, f)\n",
    "\n",
    "with open('./video-classes/Y_data.json', 'w') as f:\n",
    "    json.dump(Y_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar os Dados JSON (junto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./video-classes/X_data.json')\n",
    "X_data_loaded = json.load(f)\n",
    "\n",
    "f = open('./video-classes/Y_data.json')\n",
    "Y_data_loaded = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferir os dados carregados com o número de classes determinada (junto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "X_data = X_data_loaded[:num_of_classes]\n",
    "Y_data = Y_data_loaded[:num_of_classes]\n",
    "print('Quantidade de classes => ' + str(len(Y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2096\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(len(X_data_train))\n",
    "print(isinstance(X_data, np.ndarray))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar os dados em JSON (separado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./video-classes-2/X_data_train.json', 'w') as f:\n",
    "    json.dump(X_data_train, f)\n",
    "\n",
    "with open('./video-classes-2/Y_data_train.json', 'w') as f:\n",
    "    json.dump(Y_data_train, f)\n",
    "\n",
    "with open('./video-classes-2/X_data_test.json', 'w') as f:\n",
    "    json.dump(X_data_test, f)\n",
    "\n",
    "with open('./video-classes-2/Y_data_test.json', 'w') as f:\n",
    "    json.dump(Y_data_test, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar os dados JSON (separado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./video-classes-2/X_data_train.json')\n",
    "X_data_train_loaded = json.load(f)\n",
    "\n",
    "f = open('./video-classes-2/Y_data_train.json')\n",
    "Y_data_train_loaded = json.load(f)\n",
    "\n",
    "f = open('./video-classes-2/X_data_test.json')\n",
    "X_data_test_loaded = json.load(f)\n",
    "\n",
    "f = open('./video-classes-2/Y_data_test.json')\n",
    "Y_data_test_loaded = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transferir os dados carregados com o número de classes determinada (separado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de vídeos p/ treino => 370\n",
      "Quantidade de vídeos p/ teste => 40\n"
     ]
    }
   ],
   "source": [
    "X_data_train = np.array(X_data_train_loaded[:train_size])\n",
    "Y_data_train = np.array(Y_data_train_loaded[:train_size])\n",
    "X_data_test  = np.array(X_data_test_loaded[:test_size])\n",
    "Y_data_test  = np.array(Y_data_test_loaded[:test_size])\n",
    "\n",
    "print('Quantidade de vídeos p/ treino => ' + str(len(Y_data_train)))\n",
    "print('Quantidade de vídeos p/ teste => ' + str(len(Y_data_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formato dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_data_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5608/3477963492.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_data_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_data_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_data_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_data_train.shape)\n",
    "print(Y_data_train.shape)\n",
    "print(Y_data_train)\n",
    "\n",
    "print(X_data_test.shape)\n",
    "print(Y_data_test.shape)\n",
    "print(Y_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embaralhamento dos dados (junto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio => 4\n",
      "ratio => 4\n",
      "(32, 12, 48, 64)\n",
      "(8, 12, 48, 64)\n",
      "(32, 12, 64, 48, 1)\n",
      "(8, 12, 64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "X_data_train = []\n",
    "Y_data_train = []\n",
    "X_data_test = []\n",
    "Y_data_test = []\n",
    "\n",
    "for i in range(num_of_classes):\n",
    "    X_aux = X_data[i]\n",
    "    Y_aux = Y_data[i]\n",
    "    X_aux, Y_aux = shuffle(X_aux, Y_aux)\n",
    "    \n",
    "    ratio = int(len(X_aux) * test_percentage)\n",
    "    print('ratio => ' + str(ratio))\n",
    "    \n",
    "    if (len(X_data_train) == 0):\n",
    "        X_data_train = X_aux[ratio:]\n",
    "        Y_data_train = Y_aux[ratio:]\n",
    "        X_data_test  = X_aux[:ratio]\n",
    "        Y_data_test  = Y_aux[:ratio]\n",
    "        \n",
    "    else:    \n",
    "        X_data_train = np.concatenate((X_data_train, X_aux[ratio:]), axis=0)\n",
    "        Y_data_train = np.concatenate((Y_data_train, Y_aux[ratio:]), axis=0)\n",
    "        X_data_test  = np.concatenate((X_data_test, X_aux[:ratio]), axis=0)\n",
    "        Y_data_test  = np.concatenate((Y_data_test, Y_aux[:ratio]), axis=0)\n",
    "\n",
    "print(X_data_train.shape)\n",
    "print(X_data_test.shape)\n",
    "train_size = X_data_train.shape[0]\n",
    "test_size = X_data_test.shape[0]\n",
    "X_data_train = X_data_train.reshape(train_size, num_of_frames, width, height, num_of_channels)\n",
    "print(np.shape(X_data_train))\n",
    "\n",
    "X_data_test = X_data_test.reshape(test_size, num_of_frames, width, height, num_of_channels)\n",
    "print(np.shape(X_data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embaralhamento dos dados (separado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data, Y_data = shuffle(X_data, Y_data)\n",
    "# print(Y_data)\n",
    "# print(X_data.shape[0])\n",
    "# print(X_data[0].shape)\n",
    "# print(X_data[1].shape)\n",
    "\n",
    "# X_data_train = X_data[173:]\n",
    "# Y_data_train = Y_data[173:]\n",
    "# X_data_test = X_data[:173]\n",
    "# Y_data_test = Y_data[:173]\n",
    "# print(Y_data_train)\n",
    "# print(Y_data_test)\n",
    "\n",
    "# print(X_data_train.shape)\n",
    "# print(X_data_test.shape)\n",
    "\n",
    "# X_data_train = X_data_train.reshape(train_size, num_of_frames, width, height, num_of_channels)\n",
    "# print(np.shape(X_data_train))\n",
    "\n",
    "# X_data_test = X_data_test.reshape(test_size, num_of_frames, width, height, num_of_channels)\n",
    "# print(np.shape(X_data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplo de frames de um vídeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ee2d10854145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# converte a imagem de numpy para Image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimage0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# converte a imagem de numpy para Image\n",
    "image0 = Image.fromarray(X_data_train[0][0])\n",
    "image1 = Image.fromarray(X_data_train[0][1])\n",
    "image2 = Image.fromarray(X_data_train[0][2])\n",
    "image3 = Image.fromarray(X_data_train[0][3])\n",
    "image4 = Image.fromarray(X_data_train[0][4])\n",
    "image5 = Image.fromarray(X_data_train[0][5])\n",
    "\n",
    "# plota as imagens\n",
    "plt.imshow(image0, 'gray')\n",
    "f, axarr = plt.subplots(1, 6)\n",
    "axarr[0].imshow(image0, 'gray')\n",
    "axarr[1].imshow(image1, 'gray')\n",
    "axarr[2].imshow(image2, 'gray')\n",
    "axarr[3].imshow(image3, 'gray')\n",
    "axarr[4].imshow(image4, 'gray')\n",
    "axarr[5].imshow(image5, 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remodelar o conjunto de dados\n",
    "Exemplo:\n",
    "So, if you have 10000 samples in total, using sets of 10 frames per input, with 30 x 30 dimensions and 1 channel of color, you may reshape your X_data like:\n",
    "\n",
    "X_data = X_data.reshape(10000, 10, 30, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 12, 64, 48, 1)\n",
      "(40, 12, 64, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "# transforma os dados dos frames armazenados no formato ideal para ser usado no treinamento\n",
    "X_data_train = X_data_train.reshape(train_size, num_of_frames, width, height, num_of_channels)\n",
    "print(np.shape(X_data_train))\n",
    "\n",
    "X_data_test = X_data_test.reshape(test_size, num_of_frames, width, height, num_of_channels)\n",
    "print(np.shape(X_data_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKBya7k0fP1C"
   },
   "source": [
    "# Definição da Rede Neural Convolucional 3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative dimension size caused by subtracting 3 from 1 for '{{node conv3d_2/Conv3D}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](Placeholder, conv3d_2/Conv3D/ReadVariableOp)' with input shapes: [?,1,12,8,50], [3,5,5,50,10].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1879\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1880\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1881\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv3d_2/Conv3D}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](Placeholder, conv3d_2/Conv3D/ReadVariableOp)' with input shapes: [?,1,12,8,50], [3,5,5,50,10].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11500/1278272258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# Constrói o modelo.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;31m# Dados do modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11500/1278272258.py\u001b[0m in \u001b[0;36mget_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaxPooling3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m    \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv3D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    215\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    974\u001b[0m     \u001b[1;31m# >> model = tf.keras.Model(inputs, outputs)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0m\u001b[0;32m    977\u001b[0m                                                 input_list)\n\u001b[0;32m    978\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[1;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         layer=self, inputs=inputs, build_graph=True, training=training_value):\n\u001b[0;32m   1113\u001b[0m       \u001b[1;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0m\u001b[0;32m   1115\u001b[0m           inputs, input_masks, args, kwargs)\n\u001b[0;32m   1116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[1;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[0;32m    846\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    847\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[1;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[0;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\layers\\convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    247\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m     name=None):\n\u001b[1;32m-> 1131\u001b[1;33m   return convolution_internal(\n\u001b[0m\u001b[0;32m   1132\u001b[0m       \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m       \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       return op(\n\u001b[0m\u001b[0;32m   1262\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1263\u001b[0m           \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36m_conv3d_expanded_batch\u001b[1;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   3127\u001b[0m     \u001b[1;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3128\u001b[0m     \u001b[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3129\u001b[1;33m     return gen_nn_ops.conv3d(\n\u001b[0m\u001b[0;32m   3130\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3131\u001b[0m         \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mconv3d\u001b[1;34m(input, filter, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   1423\u001b[0m         \"'conv3d' Op, not %r.\" % dilations)\n\u001b[0;32m   1424\u001b[0m   \u001b[0mdilations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dilations\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_i\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdilations\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1425\u001b[1;33m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[0;32m   1426\u001b[0m         \u001b[1;34m\"Conv3D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1427\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    746\u001b[0m       \u001b[1;31m# Add Op to graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 748\u001b[1;33m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[0;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    600\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         compute_device)\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3559\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3560\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3561\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3562\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3563\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2039\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2042\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2043\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1881\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv3d_2/Conv3D}} = Conv3D[T=DT_FLOAT, data_format=\"NDHWC\", dilations=[1, 1, 1, 1, 1], padding=\"VALID\", strides=[1, 1, 1, 1, 1]](Placeholder, conv3d_2/Conv3D/ReadVariableOp)' with input shapes: [?,1,12,8,50], [3,5,5,50,10]."
     ]
    }
   ],
   "source": [
    " def get_model():\n",
    "    \n",
    "    # Camadas do modelo\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Conv3D(50, (5,7,7), activation='relu', input_shape=(9, width, height, num_of_channels)))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPooling3D((1, 2, 2), padding='same'))\n",
    "\n",
    "    model.add(keras.layers.Conv3D(50, (5,7,7), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.MaxPooling3D((1, 2, 2), padding='same'))\n",
    "    \n",
    "    model.add(keras.layers.Conv3D(10, (3,5,5), activation='relu'))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(200, activation='sigmoid'))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Dense(num_of_classes, activation='sigmoid', use_bias=True))\n",
    "    \n",
    "    # Compilação do modelo\n",
    "    \n",
    "    initial_learning_rate = 0.0001\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "    \n",
    "#     model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Constrói o modelo.\n",
    "model = get_model()\n",
    "\n",
    "# Dados do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A1cqOPuch3qC"
   },
   "source": [
    "# Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lo5Qoi4SJ-0N",
    "outputId": "6d2f5ac0-de3d-42ea-e579-2c84d9af5029",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# epochs = 100\n",
    "# model.fit(X_data_train, Y_data_train, epochs=epochs, batch_size=train_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo até determinada acurácia (separado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "accuracy = 0\n",
    "while accuracy < 0.6:\n",
    "    model.fit(X_data_train, Y_data_train, epochs=epochs, batch_size=train_size, shuffle=True)\n",
    "    result = model.evaluate(X_data_test, Y_data_test)\n",
    "    if (result[1] > accuracy):\n",
    "        model.save('./model-2/')\n",
    "        accuracy = result[1]\n",
    "    print(result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento do modelo até determinada acurácia, com dados de entrada aleatórios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8722 - acc: 0.4688\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.6616 - acc: 0.6562\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 0.4235 - acc: 0.7812\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.3854 - acc: 0.7812\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.3271 - acc: 0.8750\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 0.2604 - acc: 0.8750\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.2456 - acc: 0.9062\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.1879 - acc: 0.9375\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.1581 - acc: 0.9688\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.1582 - acc: 0.9688\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 0.1063 - acc: 0.9688\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.1114 - acc: 0.9688\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.0845 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.0611 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.0961 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.0522 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.0354 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0499 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0422 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0281 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0399 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0120 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0107 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0018 - acc: 1.0000\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 0.0200 - acc: 1.0000\n",
      "INFO:tensorflow:Assets written to: ./model/assets\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "accuracy = 0\n",
    "while accuracy < 0.6:\n",
    "    X_data_train = []\n",
    "    Y_data_train = []\n",
    "    X_data_test = []\n",
    "    Y_data_test = []\n",
    "\n",
    "    for i in range(num_of_classes):\n",
    "        X_aux = X_data[i]\n",
    "        Y_aux = Y_data[i]\n",
    "        X_aux, Y_aux = shuffle(X_aux, Y_aux)\n",
    "\n",
    "        ratio = int(len(X_aux) * 0.2)\n",
    "\n",
    "        if (len(X_data_train) == 0):\n",
    "            X_data_train = X_aux[ratio:]\n",
    "            Y_data_train = Y_aux[ratio:]\n",
    "            X_data_test  = X_aux[:ratio]\n",
    "            Y_data_test  = Y_aux[:ratio]\n",
    "        else:    \n",
    "            X_data_train = np.concatenate((X_data_train, X_aux[ratio:]), axis=0)\n",
    "            Y_data_train = np.concatenate((Y_data_train, Y_aux[ratio:]), axis=0)\n",
    "            X_data_test  = np.concatenate((X_data_test, X_aux[:ratio]), axis=0)\n",
    "            Y_data_test  = np.concatenate((Y_data_test, Y_aux[:ratio]), axis=0)\n",
    "\n",
    "    train_size = X_data_train.shape[0]\n",
    "    test_size  = X_data_test.shape[0]\n",
    "    \n",
    "    X_data_train = X_data_train.reshape(train_size, num_of_frames, width, height, num_of_channels)\n",
    "    X_data_test  = X_data_test.reshape(test_size, num_of_frames, width, height, num_of_channels)\n",
    "\n",
    "    model.fit(X_data_train, Y_data_train, epochs=epochs, batch_size=train_size, shuffle=True)\n",
    "    result = model.evaluate(X_data_test, Y_data_test)\n",
    "    if (result[1] > accuracy):\n",
    "        model.save('./model/')\n",
    "        accuracy = result[1]\n",
    "    print(result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step - loss: 0.3342 - acc: 0.9167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33415135741233826, 0.9166666865348816]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_data_test, Y_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
      "58.24 ==> A\n",
      "18.79 ==> B\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(np.expand_dims(X_data_test[0], axis=0))[0]\n",
    "print(Y_data_test)\n",
    "for predict, name in zip(prediction, class_names):\n",
    "    print(\n",
    "        \"%.2f ==> %s\"\n",
    "        % ((100 * predict), name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salvar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel = keras.models.load_model('./model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 23ms/step - loss: 0.9130 - acc: 0.9765\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9129856824874878, 0.9764705896377563]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newModel.evaluate(X_data_test, Y_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3dcnn-sign-language-test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
